{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rshafi_assignment.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXJlKXqhmQwk",
        "outputId": "d34ac53e-fe61-4de1-8538-9988ac5fc957"
      },
      "source": [
        "% pip install jarvis-md"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jarvis-md\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/8c/c0e9a5cc4840e50d0743824996f84a95922c4e21a71a991572323328df9e/jarvis_md-0.0.1a14-py3-none-any.whl (81kB)\n",
            "\r\u001b[K     |████                            | 10kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 20kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 30kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 40kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (2.23.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (3.1.0)\n",
            "Collecting pyyaml>=5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 10.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.19.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2.10)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->jarvis-md) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->jarvis-md) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->jarvis-md) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->jarvis-md) (1.15.0)\n",
            "Installing collected packages: pyyaml, jarvis-md\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed jarvis-md-0.0.1a14 pyyaml-5.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meqzQGeBnuWH"
      },
      "source": [
        "import os, numpy as np, pandas as pd\n",
        "from tensorflow import losses, optimizers\n",
        "from tensorflow.keras import Input, Model, models, layers\n",
        "from jarvis.train import datasets, custom"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWls49VxnvWu",
        "outputId": "005ed7dd-7fdd-46ef-994b-f08aef433638"
      },
      "source": [
        "datasets.download(name='mr/brats-2020-096')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2021-06-08 00:27:03 ] [====================] 100.000% : Extracting archive (0000486 / 0000486) "
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'code': '/data/raw/mr_brats_2020', 'data': '/data/raw/mr_brats_2020'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-yDuiM6RdQq"
      },
      "source": [
        "# Global Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mizyY93Qnxpe"
      },
      "source": [
        "gen_train, gen_valid, client = datasets.prepare(name='mr/brats-2020-096', keyword='096*glb-org')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1FI8XnY0zHG"
      },
      "source": [
        "kwargs = {\n",
        "    'kernel_size': (3, 3, 3),\n",
        "    'padding': 'same'}\n",
        "\n",
        "# --- Define lambda functions\n",
        "conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
        "norm = lambda x : layers.BatchNormalization()(x)\n",
        "relu = lambda x : layers.ReLU()(x)\n",
        "tran = lambda x, filters, strides : layers.Conv3DTranspose(filters=filters, strides=strides, **kwargs)(x)\n",
        "\n",
        "# --- Define stride-1, stride-2 blocks\n",
        "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
        "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=2)))\n",
        "tran2 = lambda filters, x : relu(norm(tran(x, filters, strides=2)))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrOXXuFc00aN"
      },
      "source": [
        "inputs = client.get_inputs(Input)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypc4M9eQoBW1"
      },
      "source": [
        "# Contracting layers\n",
        "l1 = conv1(16, inputs['dat'])\n",
        "l2 = conv1(24, conv2(24, l1))\n",
        "l3 = conv1(32, conv2(32, l2))\n",
        "l4 = conv1(48, conv2(48, l3))\n",
        "l5 = conv1(64, conv2(64, l4))\n",
        "\n",
        "f0 = layers.Flatten()(l5)\n",
        "\n",
        "# --- Create logits\n",
        "logits = {}\n",
        "logits['survival'] = layers.Dense(1, activation = 'sigmoid', name='survival')(f0)\n",
        "\n",
        "# --- Create model\n",
        "model = Model(inputs=inputs, outputs=logits) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eCT35wiB9UR"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=2e-4),\n",
        "    loss={'survival': losses.MeanSquaredError()},\n",
        "    experimental_run_tf_function=False)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq964VJkB-Ze"
      },
      "source": [
        "# --- Train model\n",
        "model.fit(\n",
        "    x=gen_train, \n",
        "    steps_per_epoch=125, \n",
        "    epochs=8,\n",
        "    validation_data=gen_valid,\n",
        "    validation_steps=125,\n",
        "    validation_freq=4,\n",
        "    use_multiprocessing=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flm5e0JsKuAQ"
      },
      "source": [
        "# --- Create validation generator\n",
        "test_train, test_valid = client.create_generators(test=True, expand=True)\n",
        "\n",
        "preds = []\n",
        "trues = []\n",
        "mae = []\n",
        "\n",
        "for x, y in test_valid:\n",
        "    \n",
        "    # --- Predict\n",
        "    logits = model.predict(x['dat'])\n",
        "\n",
        "    if type(logits) is dict:\n",
        "        logits = logits['survival']\n",
        "\n",
        "    # --- Aggregate\n",
        "    preds.append(logits.ravel())\n",
        "    trues.append(y['survival'].ravel())\n",
        "    mae.append(np.abs(preds[-1] - trues[-1]))\n",
        "\n",
        "preds = np.array(preds).ravel()\n",
        "trues = np.array(trues).ravel()\n",
        "mae = np.array(mae).ravel()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1ScN2eRKx51"
      },
      "source": [
        "# --- Define columns\n",
        "df = pd.DataFrame(index=np.arange(mae.size))\n",
        "df['MAE'] = mae\n",
        "\n",
        "# --- Print accuracy\n",
        "print(df['MAE'].median())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJVL-EdSQ39Z"
      },
      "source": [
        "model.save('./rshafi_model_1.hdf5')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHs_s2N1RrkG"
      },
      "source": [
        "# Standard Autoencoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J89-BjAtRmma"
      },
      "source": [
        "gen_train, gen_valid, client = datasets.prepare(name='mr/brats-2020-096', keyword='096*glb-org')"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP4xKxXjVkbI"
      },
      "source": [
        "inputs = client.get_inputs(Input)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHF1Xg1qScoa"
      },
      "source": [
        "# --- Define contracting layers\n",
        "l1 = conv1(8, inputs['dat'])\n",
        "l2 = conv1(16, conv2(16, l1))\n",
        "l3 = conv1(32, conv2(32, l2))\n",
        "l4 = conv1(48, conv2(48, l3))\n",
        "l5 = conv1(64, conv2(64, l4))\n",
        " \n",
        "# --- Define expanding layers\n",
        "l6  = tran2(48, l5)\n",
        "l7  = tran2(32, conv1(48, l6))\n",
        "l8  = tran2(16, conv1(32, l7))\n",
        "l9  = tran2(8,  conv1(16, l8))\n",
        "l10 = conv1(8,  l9)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggeiJao8Sfn-"
      },
      "source": [
        "logits = {'recon': layers.Conv3D(filters=4, name='recon', **kwargs)(l10)}\n",
        "ae = Model(inputs=inputs, outputs=logits)\n",
        " \n",
        "# --- Create encoder\n",
        "encoder = Model(inputs=inputs, outputs=l5)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGZRNyNITiiX"
      },
      "source": [
        "def ae_generator(G):\n",
        "    \"\"\"\n",
        "    Method to modify standard generator for autoencoder\n",
        "    \n",
        "    \"\"\"\n",
        "    for xs, ys in G:\n",
        "\n",
        "        ys = {'recon': xs['dat']}\n",
        "\n",
        "        yield xs, ys"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs3vLMWITk4N"
      },
      "source": [
        "# --- Compile model\n",
        "ae.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=1e-3),\n",
        "    loss={'recon': losses.MeanSquaredError()},\n",
        "    experimental_run_tf_function=False)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKojVwXFTvpg"
      },
      "source": [
        "# --- Train model\n",
        "ae.fit(\n",
        "    x=ae_generator(gen_train), \n",
        "    steps_per_epoch=250, \n",
        "    epochs=4,\n",
        "    use_multiprocessing=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NezC9Ei8b0Av"
      },
      "source": [
        "# --- Freeze encoder model weights\n",
        "encoder.trainable = False"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67GinaBHcS-4"
      },
      "source": [
        "# --- Re-use the encoder model layers on input\n",
        "latent = encoder(inputs)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRkUyCuycUue"
      },
      "source": [
        "# --- Finalize model\n",
        "h0 = layers.Flatten()(latent)\n",
        "h1 = layers.Dense(32, activation='relu')(h0)\n",
        "\n",
        "logits = {}\n",
        "logits['survival'] = layers.Dense(1, activation='sigmoid', name='survival')(h1)\n",
        "\n",
        "# --- Create encoder\n",
        "model = Model(inputs=inputs, outputs=logits)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV8gWpz9cYL6"
      },
      "source": [
        "# --- Compile model\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=2e-4),\n",
        "    loss={'survival': losses.MeanSquaredError()},\n",
        "    experimental_run_tf_function=False)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oQgqnm_caP4"
      },
      "source": [
        "# --- Train model\n",
        "model.fit(\n",
        "    x=gen_train, \n",
        "    steps_per_epoch=125, \n",
        "    epochs=4,\n",
        "    validation_data=gen_valid,\n",
        "    validation_steps=125,\n",
        "    validation_freq=2,\n",
        "    use_multiprocessing=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inSoBrSXcbxK"
      },
      "source": [
        "# --- Create validation generator\n",
        "test_train, test_valid = client.create_generators(test=True, expand=True)\n",
        "\n",
        "preds = []\n",
        "trues = []\n",
        "mae = []\n",
        "\n",
        "for x, y in test_valid:\n",
        "    \n",
        "    # --- Predict\n",
        "    logits = model.predict(x['dat'])\n",
        "\n",
        "    if type(logits) is dict:\n",
        "        logits = logits['survival']\n",
        "\n",
        "    # --- Aggregate\n",
        "    preds.append(logits.ravel())\n",
        "    trues.append(y['survival'].ravel())\n",
        "    mae.append(np.abs(preds[-1] - trues[-1]))\n",
        "\n",
        "preds = np.array(preds).ravel()\n",
        "trues = np.array(trues).ravel()\n",
        "mae = np.array(mae).ravel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-3r82aKiXA4"
      },
      "source": [
        "# --- Define columns\n",
        "df = pd.DataFrame(index=np.arange(mae.size))\n",
        "df['MAE'] = mae\n",
        "\n",
        "# --- Print accuracy\n",
        "print(df['MAE'].median())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IWUPcdsiaE9"
      },
      "source": [
        "model.save('./rshafi_model_2.hdf5')"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyWQzmwml0Lz"
      },
      "source": [
        "#Fully-convolutional Network\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K56evg0sl2QB"
      },
      "source": [
        "# --- Create custom configs dict\n",
        "configs = {'specs': {'ys': {\n",
        "    'tumor': {\n",
        "        'dtype': 'uint8',\n",
        "        'loads': 'lbl-crp',\n",
        "        'norms': {'clip': {'min': 0, 'max': 1}},\n",
        "        'shape': [96, 96, 96, 1]},\n",
        "    'survival': {\n",
        "        'dtype': 'float32',\n",
        "        'loads': 'survival_days_norm',\n",
        "        'shape': [1]}}}}\n",
        "\n",
        "# --- Create generators\n",
        "gen_train, gen_valid, client = datasets.prepare(\n",
        "    name='mr/brats-2020-096', \n",
        "    keyword='096*vox-org',\n",
        "    configs=configs)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRGd1p4LmgBW"
      },
      "source": [
        "inputs = client.get_inputs(Input)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIFoonhCmi3q"
      },
      "source": [
        "# --- Define contracting layers\n",
        "l1 = conv1(8, inputs['dat'])\n",
        "l2 = conv1(16, conv2(16, l1))\n",
        "l3 = conv1(32, conv2(32, l2))\n",
        "l4 = conv1(48, conv2(48, l3))\n",
        "l5 = conv1(64, conv2(64, l4))\n",
        " \n",
        "# --- Define expanding layers\n",
        "l6  = tran2(48, l5)\n",
        "l7  = tran2(32, conv1(48,l6))\n",
        "l8  = tran2(16, conv1(32, l7))\n",
        "l9  = tran2(8,  conv1(16, l8))\n",
        "l10 = conv1(8,  l9)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDmKRClcmrDI"
      },
      "source": [
        "# --- Create model\n",
        "logits = {}\n",
        "logits['survival'] = layers.Conv3D(filters=1, name='survival', activation='sigmoid', **kwargs)(l10)\n",
        "logits['tumor'] = layers.Conv3D(filters=2, name='tumor', **kwargs)(l10)\n",
        "model = Model(inputs=inputs, outputs=logits)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3bLInkhoAok"
      },
      "source": [
        "def generator(G):\n",
        "    \"\"\"\n",
        "    Method to modify combined generator \n",
        " \n",
        "    \"\"\"\n",
        "    for xs, ys in G:\n",
        " \n",
        "        # --- Reshape survival/tumor to 5D tensor\n",
        "        survival = ys['survival'].reshape(-1, 1, 1, 1, 1)\n",
        "        tumor = ys['tumor'].reshape(-1, 1, 1, 1, 1)\n",
        " \n",
        "        # --- Replace ys['survival']/ys['tumor']\n",
        "        ys['survival'] = np.zeros((survival.shape[0], 96, 96, 96, 1), dtype='float32')\n",
        "        ys['survival'][:] = survival\n",
        "        ys['tumor'] = np.zeros((survival.shape[0], 96, 96, 96, 1), dtype='float32')\n",
        "        ys['tumor'][:] = survival\n",
        " \n",
        "        yield xs, ys"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDGo34N4oMfz"
      },
      "source": [
        "# --- Compile model\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=2e-4),\n",
        "    loss={\n",
        "        'survival': losses.MeanSquaredError(),\n",
        "        'tumor': losses.SparseCategoricalCrossentropy(from_logits=True)},\n",
        "    experimental_run_tf_function=False)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkdlr6lSoPCF"
      },
      "source": [
        "model.fit(x=generator(gen_train),\n",
        "          steps_per_epoch=125, \n",
        "          epochs=8,\n",
        "          use_multiprocessing=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvvMKGz5x5SJ"
      },
      "source": [
        "# --- Create validation generator\n",
        "test_train, test_valid = client.create_generators(test=True, expand=True)\n",
        "\n",
        "preds = []\n",
        "trues = []\n",
        "mae = []\n",
        "\n",
        "for x, y in test_valid:\n",
        "    \n",
        "    # --- Predict\n",
        "    logits = model.predict(x['dat'])\n",
        "\n",
        "    if type(logits) is dict:\n",
        "        logits = logits['survival']\n",
        "\n",
        "    # --- Aggregate\n",
        "    preds.append(logits.ravel())\n",
        "    trues.append(y['survival'].ravel())\n",
        "    mae.append(np.abs(preds[-1] - trues[-1]))\n",
        "\n",
        "preds = np.array(preds).ravel()\n",
        "trues = np.array(trues).ravel()\n",
        "mae = np.array(mae).ravel()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OroCMm_ny2v0"
      },
      "source": [
        "# --- Define columns\n",
        "df = pd.DataFrame(index=np.arange(mae.size))\n",
        "df['MAE'] = mae\n",
        "\n",
        "# --- Print accuracy\n",
        "print(df['MAE'].median())"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9jwQ8kG364a"
      },
      "source": [
        "model.save('./rshafi_model_3.hdf5')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueKnN4eY3nut"
      },
      "source": [
        "#Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvlYk2fHGvfV"
      },
      "source": [
        "##Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR6705v63o3H"
      },
      "source": [
        "model = models.load_model('./rshafi_model_1.hdf5')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYFiwGF2ASyN"
      },
      "source": [
        "gen_train, gen_valid, client = datasets.prepare(name='mr/brats-2020-096', keyword='096*glb-org')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OtP6mjMBsp1",
        "outputId": "16b8b988-9b58-4466-fa03-769be799fb21"
      },
      "source": [
        "# --- Create validation generator\n",
        "test_train, test_valid = client.create_generators(test=True, expand=True)\n",
        "\n",
        "preds = []\n",
        "trues = []\n",
        "mae = []\n",
        "validation_size = 0\n",
        "training_size = 0\n",
        "for x, y in test_valid:\n",
        "\n",
        "    validation_size += 1\n",
        "    # --- Predict\n",
        "    logits = model.predict(x['dat'])\n",
        "\n",
        "    if type(logits) is dict:\n",
        "        logits = logits['survival']\n",
        "\n",
        "    # --- Aggregate\n",
        "    preds.append(logits.ravel())\n",
        "    trues.append(y['survival'].ravel())\n",
        "    mae.append(np.abs(preds[-1] - trues[-1]))\n",
        "\n",
        "preds = np.array(preds).ravel()\n",
        "trues = np.array(trues).ravel()\n",
        "mae = np.array(mae).ravel()\n",
        "\n",
        "preds_train = []\n",
        "trues_train = []\n",
        "mae_train = []\n",
        "\n",
        "for x, y in test_train:\n",
        "    \n",
        "    training_size += 1\n",
        "    # --- Predict\n",
        "    logits = model.predict(x['dat'])\n",
        "\n",
        "    if type(logits) is dict:\n",
        "        logits = logits['survival']\n",
        "\n",
        "    # --- Aggregate\n",
        "    preds_train.append(logits.ravel())\n",
        "    trues_train.append(y['survival'].ravel())\n",
        "    mae_train.append(np.abs(preds_train[-1] - trues_train[-1]))\n",
        "\n",
        "preds_train = np.array(preds_train).ravel()\n",
        "trues_train = np.array(trues_train).ravel()\n",
        "mae_train = np.array(mae_train).ravel()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2021-06-08 00:29:09 ] [====================] 100.000% : Iterating | 000185    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgfQZXr3ByoO",
        "outputId": "28eb4d11-bb8f-48ff-eea9-80095e1a1ad5"
      },
      "source": [
        "# --- Define columns\n",
        "df = pd.DataFrame(index=np.arange(mae.size))\n",
        "df['MAE'] = mae\n",
        "print(\"Size of validation dataset: \", validation_size)\n",
        "# --- Print accuracy (validation)\n",
        "print(df['MAE'].median())\n",
        "print(df['MAE'].mean())\n",
        "print(df['MAE'].quantile(0.25))\n",
        "print(df['MAE'].quantile(0.75))\n",
        "print(\"Size of training dataset: \", training_size)\n",
        "# --- Print accuracy (training)\n",
        "df = pd.DataFrame(index=np.arange(mae_train.size))\n",
        "df['MAET'] = mae_train\n",
        "print(df['MAET'].median())\n",
        "print(df['MAET'].mean())\n",
        "print(df['MAET'].quantile(0.25))\n",
        "print(df['MAET'].quantile(0.75))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of validation dataset:  50\n",
            "0.06436899304389954\n",
            "0.08401628583669662\n",
            "0.028337106108665466\n",
            "0.11981521546840668\n",
            "Size of training dataset:  185\n",
            "0.07638853788375854\n",
            "0.08996275812387466\n",
            "0.052431344985961914\n",
            "0.10954666137695312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tmPtZiqAkZR",
        "outputId": "1fab233b-374a-4b2a-cbc5-11417a722b2b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dat (InputLayer)             [(None, 96, 96, 96, 4)]   0         \n",
            "_________________________________________________________________\n",
            "conv3d (Conv3D)              (None, 96, 96, 96, 16)    1744      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 96, 96, 96, 16)    64        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 96, 96, 96, 16)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 48, 48, 48, 24)    10392     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 48, 48, 48, 24)    96        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 48, 48, 48, 24)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 48, 48, 48, 24)    15576     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 48, 48, 24)    96        \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 48, 48, 48, 24)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 24, 24, 24, 32)    20768     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 24, 24, 32)    128       \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 24, 24, 24, 32)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_4 (Conv3D)            (None, 24, 24, 24, 32)    27680     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 24, 24, 24, 32)    128       \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 24, 24, 24, 32)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_5 (Conv3D)            (None, 12, 12, 12, 48)    41520     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 12, 12, 12, 48)    192       \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 12, 12, 12, 48)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_6 (Conv3D)            (None, 12, 12, 12, 48)    62256     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 12, 12, 12, 48)    192       \n",
            "_________________________________________________________________\n",
            "re_lu_6 (ReLU)               (None, 12, 12, 12, 48)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_7 (Conv3D)            (None, 6, 6, 6, 64)       83008     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 6, 6, 6, 64)       256       \n",
            "_________________________________________________________________\n",
            "re_lu_7 (ReLU)               (None, 6, 6, 6, 64)       0         \n",
            "_________________________________________________________________\n",
            "conv3d_8 (Conv3D)            (None, 6, 6, 6, 64)       110656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 6, 6, 6, 64)       256       \n",
            "_________________________________________________________________\n",
            "re_lu_8 (ReLU)               (None, 6, 6, 6, 64)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 13824)             0         \n",
            "_________________________________________________________________\n",
            "survival (Dense)             (None, 1)                 13825     \n",
            "=================================================================\n",
            "Total params: 388,833\n",
            "Trainable params: 388,129\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBvA4_Q_Eeje"
      },
      "source": [
        "##Model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cVbq-GREfag"
      },
      "source": [
        "model = models.load_model('./rshafi_model_2.hdf5')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juPBNYq8Aat-"
      },
      "source": [
        "gen_train, gen_valid, client = datasets.prepare(name='mr/brats-2020-096', keyword='096*glb-org')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs2Dd2oeFchv",
        "outputId": "cfa70191-ce96-4a0a-fd4e-d20054acfd7a"
      },
      "source": [
        "# --- Create validation generator\n",
        "test_train, test_valid = client.create_generators(test=True, expand=True)\n",
        "\n",
        "preds = []\n",
        "trues = []\n",
        "mae = []\n",
        "\n",
        "for x, y in test_valid:\n",
        "    \n",
        "    # --- Predict\n",
        "    logits = model.predict(x['dat'])\n",
        "\n",
        "    if type(logits) is dict:\n",
        "        logits = logits['survival']\n",
        "\n",
        "    # --- Aggregate\n",
        "    preds.append(logits.ravel())\n",
        "    trues.append(y['survival'].ravel())\n",
        "    mae.append(np.abs(preds[-1] - trues[-1]))\n",
        "    \n",
        "preds = np.array(preds).ravel()\n",
        "trues = np.array(trues).ravel()\n",
        "mae = np.array(mae).ravel()\n",
        "\n",
        "preds_train = []\n",
        "trues_train = []\n",
        "mae_train = []\n",
        "\n",
        "for x, y in test_train:\n",
        "    \n",
        "    # --- Predict\n",
        "    logits = model.predict(x['dat'])\n",
        "\n",
        "    if type(logits) is dict:\n",
        "        logits = logits['survival']\n",
        "\n",
        "    # --- Aggregate\n",
        "    preds_train.append(logits.ravel())\n",
        "    trues_train.append(y['survival'].ravel())\n",
        "    mae_train.append(np.abs(preds_train[-1] - trues_train[-1]))\n",
        "\n",
        "preds_train = np.array(preds_train).ravel()\n",
        "trues_train = np.array(trues_train).ravel()\n",
        "mae_train = np.array(mae_train).ravel()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2021-06-08 00:29:42 ] [====================] 100.000% : Iterating | 000185    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZWqnkFQFnqC",
        "outputId": "5f94806a-5d16-40ac-b805-9479481fa27e"
      },
      "source": [
        "# --- Define columns\n",
        "df = pd.DataFrame(index=np.arange(mae.size))\n",
        "df['MAE'] = mae\n",
        "print(\"Size of validation dataset: \", validation_size)\n",
        "# --- Print accuracy (validation)\n",
        "print(df['MAE'].median())\n",
        "print(df['MAE'].mean())\n",
        "print(df['MAE'].quantile(0.25))\n",
        "print(df['MAE'].quantile(0.75))\n",
        "print(\"Size of training dataset: \", training_size)\n",
        "# --- Print accuracy (training)\n",
        "df = pd.DataFrame(index=np.arange(mae_train.size))\n",
        "df['MAET'] = mae_train\n",
        "print(df['MAET'].median())\n",
        "print(df['MAET'].mean())\n",
        "print(df['MAET'].quantile(0.25))\n",
        "print(df['MAET'].quantile(0.75))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of validation dataset:  50\n",
            "0.051491230726242065\n",
            "0.05621673911809921\n",
            "0.025715917348861694\n",
            "0.07968433201313019\n",
            "Size of training dataset:  185\n",
            "0.020265579223632812\n",
            "0.030029529705643654\n",
            "0.010300695896148682\n",
            "0.03207427263259888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi5iTbDhAmR8",
        "outputId": "56aa6619-58e0-4599-de0a-98083008914c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dat (InputLayer)             [(None, 96, 96, 96, 4)]   0         \n",
            "_________________________________________________________________\n",
            "model_1 (Functional)         (None, 6, 6, 6, 64)       351560    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 13824)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                442400    \n",
            "_________________________________________________________________\n",
            "survival (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 793,993\n",
            "Trainable params: 442,433\n",
            "Non-trainable params: 351,560\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhgtJ3zEGra0"
      },
      "source": [
        "##Model 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlnB-En3GsM2"
      },
      "source": [
        "model = models.load_model('./rshafi_model_3.hdf5')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChpXi8_UAc9y"
      },
      "source": [
        "# --- Create custom configs dict\n",
        "configs = {'specs': {'ys': {\n",
        "    'tumor': {\n",
        "        'dtype': 'uint8',\n",
        "        'loads': 'lbl-crp',\n",
        "        'norms': {'clip': {'min': 0, 'max': 1}},\n",
        "        'shape': [96, 96, 96, 1]},\n",
        "    'survival': {\n",
        "        'dtype': 'float32',\n",
        "        'loads': 'survival_days_norm',\n",
        "        'shape': [1]}}}}\n",
        "\n",
        "# --- Create generators\n",
        "gen_train, gen_valid, client = datasets.prepare(\n",
        "    name='mr/brats-2020-096', \n",
        "    keyword='096*vox-org',\n",
        "    configs=configs)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh1i0iFWG1c1",
        "outputId": "7cd16e80-ee7d-4ddf-810f-86aa80ae74ff"
      },
      "source": [
        "# --- Create validation generator\n",
        "test_train, test_valid = client.create_generators(test=True, expand=True)\n",
        "\n",
        "preds = []\n",
        "trues = []\n",
        "mae = []\n",
        "\n",
        "for x, y in test_valid:\n",
        "    \n",
        "    # --- Predict\n",
        "    logits = model.predict(x['dat'])\n",
        "\n",
        "    if type(logits) is dict:\n",
        "        logits = logits['survival']\n",
        "\n",
        "    # --- Aggregate\n",
        "    preds.append(logits.ravel())\n",
        "    trues.append(y['survival'].ravel())\n",
        "    mae.append(np.abs(preds[-1] - trues[-1]))\n",
        "\n",
        "preds = np.array(preds).ravel()\n",
        "trues = np.array(trues).ravel()\n",
        "mae = np.array(mae).ravel()\n",
        "\n",
        "preds_train = []\n",
        "trues_train = []\n",
        "mae_train = []\n",
        "\n",
        "for x, y in test_train:\n",
        "    \n",
        "    # --- Predict\n",
        "    logits = model.predict(x['dat'])\n",
        "\n",
        "    if type(logits) is dict:\n",
        "        logits = logits['survival']\n",
        "\n",
        "    # --- Aggregate\n",
        "    preds_train.append(logits.ravel())\n",
        "    trues_train.append(y['survival'].ravel())\n",
        "    mae_train.append(np.abs(preds_train[-1] - trues_train[-1]))\n",
        "\n",
        "preds_train = np.array(preds_train).ravel()\n",
        "trues_train = np.array(trues_train).ravel()\n",
        "mae_train = np.array(mae_train).ravel()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2021-06-08 00:30:23 ] [====================] 100.000% : Iterating | 000185    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsBZOye1G2pj",
        "outputId": "ab3dcf29-1830-4511-9806-a48485160fd2"
      },
      "source": [
        "# --- Define columns\n",
        "df = pd.DataFrame(index=np.arange(mae.size))\n",
        "df['MAE'] = mae\n",
        "print(\"Size of validation dataset: \", validation_size)\n",
        "# --- Print accuracy (validation)\n",
        "print(df['MAE'].median())\n",
        "print(df['MAE'].mean())\n",
        "print(df['MAE'].quantile(0.25))\n",
        "print(df['MAE'].quantile(0.75))\n",
        "print(\"Size of training dataset: \", training_size)\n",
        "# --- Print accuracy (training)\n",
        "df = pd.DataFrame(index=np.arange(mae_train.size))\n",
        "df['MAET'] = mae_train\n",
        "print(df['MAET'].median())\n",
        "print(df['MAET'].mean())\n",
        "print(df['MAET'].quantile(0.25))\n",
        "print(df['MAET'].quantile(0.75))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of validation dataset:  50\n",
            "0.049898386001586914\n",
            "0.05688264220952988\n",
            "0.026019632816314697\n",
            "0.08414971828460693\n",
            "Size of training dataset:  185\n",
            "0.057033658027648926\n",
            "0.03419819846749306\n",
            "0.022500336170196533\n",
            "0.1128864586353302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JERQnxLaAoKo",
        "outputId": "b440dba7-ce1c-4875-df3d-430762db1b32"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "dat (InputLayer)                [(None, 96, 96, 96,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv3d (Conv3D)                 (None, 96, 96, 96, 8 872         dat[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 96, 96, 96, 8 32          conv3d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu (ReLU)                    (None, 96, 96, 96, 8 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1 (Conv3D)               (None, 48, 48, 48, 1 3472        re_lu[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 48, 48, 48, 1 64          conv3d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_1 (ReLU)                  (None, 48, 48, 48, 1 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2 (Conv3D)               (None, 48, 48, 48, 1 6928        re_lu_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 48, 48, 48, 1 64          conv3d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_2 (ReLU)                  (None, 48, 48, 48, 1 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_3 (Conv3D)               (None, 24, 24, 24, 3 13856       re_lu_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 24, 24, 24, 3 128         conv3d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_3 (ReLU)                  (None, 24, 24, 24, 3 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_4 (Conv3D)               (None, 24, 24, 24, 3 27680       re_lu_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 24, 24, 24, 3 128         conv3d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_4 (ReLU)                  (None, 24, 24, 24, 3 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_5 (Conv3D)               (None, 12, 12, 12, 4 41520       re_lu_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 12, 12, 12, 4 192         conv3d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_5 (ReLU)                  (None, 12, 12, 12, 4 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_6 (Conv3D)               (None, 12, 12, 12, 4 62256       re_lu_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 12, 12, 12, 4 192         conv3d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_6 (ReLU)                  (None, 12, 12, 12, 4 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_7 (Conv3D)               (None, 6, 6, 6, 64)  83008       re_lu_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 6, 6, 6, 64)  256         conv3d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_7 (ReLU)                  (None, 6, 6, 6, 64)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_8 (Conv3D)               (None, 6, 6, 6, 64)  110656      re_lu_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 6, 6, 6, 64)  256         conv3d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_8 (ReLU)                  (None, 6, 6, 6, 64)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_transpose (Conv3DTranspo (None, 12, 12, 12, 4 82992       re_lu_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 12, 12, 12, 4 192         conv3d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_9 (ReLU)                  (None, 12, 12, 12, 4 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_9 (Conv3D)               (None, 12, 12, 12, 4 62256       re_lu_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 12, 12, 12, 4 192         conv3d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_10 (ReLU)                 (None, 12, 12, 12, 4 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_transpose_1 (Conv3DTrans (None, 24, 24, 24, 3 41504       re_lu_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 24, 24, 24, 3 128         conv3d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_11 (ReLU)                 (None, 24, 24, 24, 3 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_10 (Conv3D)              (None, 24, 24, 24, 3 27680       re_lu_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 24, 24, 24, 3 128         conv3d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_12 (ReLU)                 (None, 24, 24, 24, 3 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_transpose_2 (Conv3DTrans (None, 48, 48, 48, 1 13840       re_lu_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 48, 48, 48, 1 64          conv3d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_13 (ReLU)                 (None, 48, 48, 48, 1 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_11 (Conv3D)              (None, 48, 48, 48, 1 6928        re_lu_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 48, 48, 48, 1 64          conv3d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_14 (ReLU)                 (None, 48, 48, 48, 1 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_transpose_3 (Conv3DTrans (None, 96, 96, 96, 8 3464        re_lu_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 96, 96, 96, 8 32          conv3d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_15 (ReLU)                 (None, 96, 96, 96, 8 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_12 (Conv3D)              (None, 96, 96, 96, 8 1736        re_lu_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 96, 96, 96, 8 32          conv3d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_16 (ReLU)                 (None, 96, 96, 96, 8 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "survival (Conv3D)               (None, 96, 96, 96, 1 217         re_lu_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tumor (Conv3D)                  (None, 96, 96, 96, 2 434         re_lu_16[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 593,443\n",
            "Trainable params: 592,371\n",
            "Non-trainable params: 1,072\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}